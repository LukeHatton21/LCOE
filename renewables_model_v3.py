import numpy as np
import warnings
import xarray as xr
import time
import csv
import os
import cartopy.crs as ccrs
import matplotlib.colors as colors
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
import math
import sys
import pandas as pd
from scipy.optimize import minimize, minimize_scalar
from joblib import Parallel, delayed
from economicmodel_v3 import Economic_Profile
from geodata_v2 import Global_Data
from filepreprocessor_v2 import All_Files
from datetime import datetime  
import os 
import regionmask


class RenewablesModel:
    def __init__(self, solar_dataset, wind_dataset, data_path, params_file, output_folder, electricity_prices, wholesale_prices, uk_prices):     
        """ Initialises the Renewables Model class, which can be used to calculate the LCOE or IRR for on a geospatial basis calculates the LCOE or IRR for different scenarios
       
        Inputs:
        Solar_dataset - hourly solar capacity factors, generated by PV_LIB
        Wind_dataset - hourly wind capacity factors, generated by RENEWABLES NINJA
        Data_path - path direction to Data inputs
        Params_file - contains the assumptions and constants used by the model
        Output_folder - folder to output results files to """


        # Read in wind and solar input files
        self.solar_data = solar_dataset
        self.wind_data = wind_dataset
        
        # Read in assumptions datafile(s)
        self.economic_profile_class = self.parameters_from_csv(params_file)
        self.renew_discount_rate = self.economic_profile_class.renew_discount_rate
        self.lifetime = 20
        self.renewables_capacity = 1000
            
        # Read in other inputs
        self.country_wacc_mapping = pd.read_csv((data_path + "new_country_waccs.csv"))
        self.country_data = xr.open_dataset((data_path + "country_grids.nc"))
        self.electricity_prices = pd.read_csv(electricity_prices)
        
        # Get Geodata file
        self.geodata_class = Global_Data((data_path + "ETOPO_bathymetry.nc"),(data_path+"distance2shore.nc"), (data_path+"country_grids.nc"), self.solar_data)
        self.geodata = self.geodata_class.get_all_data_variables()
        
        # Read in wholesale prices
        self.eu_wholesale_prices = pd.read_csv(wholesale_prices)
        self.uk_wholesale_prices = pd.read_csv(uk_prices)
        
        

        
    
    
    def parameters_from_csv(self, file_path):
        try:
            with open(file_path, 'r') as file:
                reader = csv.reader(file)
                next(reader)  # skip the header row
                params = {}
                for row in reader:
                    if len(row) == 2:
                        param_name = row[0].strip()
                        param_value = row[1].strip()
                        try:
                            param_value = float(param_value)
                            if param_value.is_integer():
                                param_value = int(param_value)
                        except ValueError:
                            pass
                        params[param_name] = param_value
                class_initiated = Economic_Profile(**params)
                self.renewables_capacity = params['renewables_capacity']
            return class_initiated
        except ValueError as e:
            print("Error: {}".format(e))
        except TypeError as f:
            print("Error: {}".format(f))
            
    def remove_high_seas(self):
        
        nan_mask_sea = xr.where(np.isnan(self.geodata['sea']), True, False)
        nan_mask_land = xr.where(np.isnan(self.geodata['land']), True, False)
        combined_nan_mask = nan_mask_sea & nan_mask_land
        return combined_nan_mask
    
            
    def discount_with_single_rate(self, data, specified_rate):
        # Read number of years, latitudes and longitudes
        years = data.sizes['year']
        latitudes = data.latitude
        longitudes = data.longitude
        years_data = data.year.values
    
        # Create array for storage
        discounted_data = xr.DataArray(
        data=None,
        dims=data.dims,
        coords=data.coords)  
        
        # Apply discounting using nested for loops
        for year in range(years):
            for count_lat, lat in enumerate(latitudes):
                for count_lon, lon in enumerate(longitudes):
                    # Get year
                    date = years_data[year]
                
                    # Discount the data with the default rate if applicable
                    discounted_data.loc[{'year': years_data[year], 'latitude': [lat], 'longitude': [lon]}] = data.loc[{'year': years_data[year], 'latitude': [lat], 'longitude': [lon]}] / ((1 + specified_rate) ** year)
                        
        return discounted_data
    
    def country_wacc_discounts(self, data, solar_capex, wind_capex):
        # Read number of years, latitudes and longitudes
        years = data.sizes['year']
        latitudes = data.latitude
        longitudes = data.longitude
        years_data = data.year.values
    
        # Create array for storage
        discounted_data = xr.DataArray(
        data=None,
        dims=data.dims,
        coords=data.coords)  
    
        for year in range(years):
            for count_lat, lat in enumerate(latitudes):
                for count_lon, lon in enumerate(longitudes):
                    # Get year
                    date = years_data[year]
                
                    # Get renewables discount rate
                    rate = self.get_country_wacc(lat, lon, solar_capex, wind_capex)
                        
                    # Check if the rate exists and if not, replace with a default
                    if np.isnan(rate) or rate == 0:
                        default_rate = self.economic_profile_class.renew_discount_rate
                                
                        # Discount the data with the default rate if applicable
                        discounted_data.loc[{'year': years_data[year], 'latitude': [lat], 'longitude': [lon]}] = data.loc[{'year': years_data[year], 'latitude': [lat], 'longitude': [lon]}] / ((1 + default_rate) ** year)
                    else:
                        discounted_data.loc[{'year': years_data[year], 'latitude': [lat], 'longitude': [lon]}] = data.loc[{'year': years_data[year], 'latitude': [lat], 'longitude': [lon]}] / ((1 + rate) ** year)
                    
        return discounted_data
    
    
    def get_country_wacc(self, lat, lon, solar_capex, wind_capex):
    
        # Retrieve CSV file with mapping of countries and waccs
        country_wacc_mappings = self.country_wacc_mapping
        geodata = self.geodata
        land_value = geodata['land'].sel({'latitude': lat, 'longitude': lon}).values 
        
        
        # Retrieve offshore mask
        if np.isnan(land_value):
            sea_value = geodata['sea'].sel({'latitude': lat, 'longitude': lon}).values 
            if np.isnan(sea_value):
                country_wacc = np.nan
            else:
                country_row = country_wacc_mappings.loc[country_wacc_mappings['index'] == sea_value]
                country_wacc = country_row.loc[country_row.index[0],'offshore wacc']
                
        else: 
            country_row = country_wacc_mappings.loc[country_wacc_mappings['index'] == land_value]
            solar_rate = country_row.loc[country_row.index[0],'solar pv wacc']
            wind_rate = country_row.loc[country_row.index[0],'onshore wacc']
            composite_rate = (solar_capex*solar_rate + wind_capex*wind_rate) / (wind_capex + solar_capex)
            country_wacc = composite_rate
        
        
        return country_wacc
        
    def extend_to_lifetime(self, data, lifetime):
        
        years = data.sizes['year'] - 1
        data = data.transpose("year", "latitude", "longitude")
        n_duplications = round(lifetime/years)
        remainder = lifetime % years
        
        # Separate 0th year and operation years 
        zeroth_year = data[0:1,:,:]
        operational_years = data[1:, :, :]
        remainder_index = remainder+1
        remainder_years = data[1:remainder_index, :, :]
        
        # Duplicate a set amount of times and then concenate over operational years
        duplicated_data = xr.concat([operational_years] * n_duplications, dim ='year')
        first_year = duplicated_data['year'][0]
        final_year = duplicated_data['year'][-1]
        year_range = final_year - first_year + 1
        duplicated_with_r = xr.concat((duplicated_data, remainder_years), dim = 'year')
        new_year_range = np.arange(first_year, (first_year + n_duplications * year_range + remainder), step = 1)
        duplicated_data =  duplicated_with_r.assign_coords({'year': new_year_range})
        
        # Concenate with the 0th year
        combined_data = xr.concat((zeroth_year, duplicated_data), dim ='year')
        # Return data
        return combined_data
    
    
    
    
    

    def parallel_levelised_cost(self, geodata, solar_data, wind_data, solar_fraction, specified_rate=None, return_prices=None, five_years=None):
        
        # Extract latitudes and longitudes
        latitudes = solar_data.latitude.values
        longitudes = solar_data.longitude.values
        
        # Setup variables required for calculation
        lifetime = self.lifetime
        
        # Call the Renewables Profile and Electrolyser Classes
        solar_profile = self.solar_data.sel(latitude=latitudes, longitude=longitudes) * self.renewables_capacity # In KWh for 1 MW
        wind_profile = self.wind_data.sel(latitude=latitudes, longitude=longitudes) * self.renewables_capacity # In KWh for 1 MW
        costs_and_output = self.economic_profile_class.calculate_costs_and_output(geodata, solar_profile, wind_profile, solar_fraction)

        
        # Access relevant yearly variables for the LCOH calculation
        electricity_output = costs_and_output['renewable_electricity'] # In KWh
        total_costs_yearly = costs_and_output['total_costs'] # For 1 MW
        
        # Extract wind and solar costs
        solar_costs_yearly = costs_and_output['solar_costs'] # For 1 MW
        wind_costs_yearly = costs_and_output['wind_costs'] # For 1 MW
        
        # If annual hydrogen output is zero, replace with a value very close to zero
        electricity_output_corrected = xr.where(electricity_output == 0, 0.001, electricity_output)
            
        
        # Extract required variables
        total_capital_cost = total_costs_yearly[0, :, :]
        solar_capital_cost = solar_costs_yearly[0, :, :]
        wind_capital_cost = wind_costs_yearly[0, :, :]                                 
        
        # Read the dimensions of the yearly output
        years = costs_and_output.sizes['year'] - 1
        
        # If the size of the data is less than the lifetime, duplicate the data
        if years < lifetime:
            n_duplicates = round(lifetime / years)
            electricity_production = self.extend_to_lifetime(electricity_output_corrected, lifetime)
            total_costs = self.extend_to_lifetime(total_costs_yearly, lifetime)
            solar_costs = self.extend_to_lifetime(solar_costs_yearly, lifetime)
            wind_costs = self.extend_to_lifetime(wind_costs_yearly, lifetime)
        
        # Discount renewables and electricity output
        if specified_rate is None:
            discounted_costs = self.country_wacc_discounts(total_costs, solar_capital_cost, wind_capital_cost) 
            discounted_output = self.country_wacc_discounts(electricity_production, solar_capital_cost, wind_capital_cost)
        else:
            discounted_costs = self.discount_with_single_rate(total_costs, specified_rate) 
            discounted_output = self.discount_with_single_rate(electricity_production, specified_rate)

            
            
        # Sum the discounted costs and hydrogen produced
        discounted_total_costs = discounted_costs.sum(dim='year')
        discounted_total_electricity = discounted_output.sum(dim='year')
        
        # Calculate the levelised cost of electricity
        levelised_cost = discounted_total_costs / discounted_total_electricity # In USD per KWh
        
        # Create dataset with results
        data_vars = {'levelised_cost': levelised_cost,
                     'capacity': "1 MW",
                     'electricity_production': electricity_production,
                     'total_capital_costs': total_capital_cost,
                     'total_costs': total_costs,
                     'solar_costs': solar_costs,
                     'wind_costs': wind_costs}
        coords = {'year': total_costs.year.values,
                  'latitude': latitudes,
                  'longitude': longitudes}
        aggregated_results = xr.Dataset(data_vars=data_vars, coords=coords)
        aggregated_results['levelised_cost'] = aggregated_results['levelised_cost'].astype(np.float64)
        
       
            ## ADD IN Code to create wholesale prices & STORE
        
        return aggregated_results
    
        
    
    def levelised_cost_grid_point(self, lat, lon, solar_fraction):
        
            # Start loop timer
            loop_start = time.time()
        
            self.high_seas = self.remove_high_seas()
            # Evaluate nature of gridpoint
            high_seas_status = self.high_seas.sel(latitude=lat, longitude=lon)
            landmask = self.geodata['land'].sel(latitude=lat, longitude=lon)

            # Check if location is sea
            if high_seas_status == True:
                return None
        
            # If solar is being examined, check if the location is in the sea
            if solar_fraction > 0:
                if np.isnan(landmask) == True:
                    return None
        
            # Get renewables data at each gridpoint
            def get_gridpoint(data, lat, lon, geodata=None):
                gridpoint = data.sel(longitude=lon, latitude=lat)
                gridpoint = gridpoint.expand_dims(latitude=[lat], longitude=[lon])
                if geodata == "True":
                    gridpoint = gridpoint.transpose("latitude", "longitude")
                else:
                    gridpoint = gridpoint.transpose("time", "latitude", "longitude")
            
                return gridpoint
        
            solar_gridpoint = get_gridpoint(self.solar_data, lat, lon)
            wind_gridpoint = get_gridpoint(self.wind_data, lat, lon)
            geodata_gridpoint = get_gridpoint(self.geodata, lat, lon, "True")
        
            # Calculate LCOE and other parameters
            aggregated_results = self.parallel_levelised_cost(geodata_gridpoint,solar_gridpoint, wind_gridpoint, solar_fraction)
        
            # Calculate loop time
            loop_end = time.time()
            loop_time = loop_end - loop_start
            return aggregated_results
    
    def global_parallel_calculation(self, num_cores, solar_fraction):
        start_time = time.time()
        latitudes = self.solar_data.latitude.values
        longitudes = self.solar_data.longitude.values
        
        # Create a list of arguments for each grid point
        grid_point_args = []
        for count_lat, lat in enumerate(latitudes):
            for count_lon, lon in enumerate(longitudes):
                grid_point_args.append((lat, lon))
    
        # Use joblib to parallelize the processing of grid points
        parallel_results = Parallel(n_jobs=num_cores, verbose=5)(delayed(self.levelised_cost_grid_point)(solar_fraction=solar_fraction, lat=lat, lon=lon) for lat, lon in grid_point_args)

        # Get the first non empty result
        first_result = next((result for result in parallel_results if result is not None), None)

        # Unpack results
        combined_dataset = None
        for result in parallel_results:
            if result is not None:
                if combined_dataset is None:
                    combined_dataset = result
                else:
                    combined_dataset = combined_dataset.combine_first(result)
            else:
                # If the result is None, create a dataset filled with NaNs
                nan_dataset = xr.zeros_like(first_result)  
                if combined_dataset is None:
                    combined_dataset = nan_dataset
                else:
                    combined_dataset = combined_dataset.combine_first(result)
        
        return combined_dataset
    
    
    def estimate_country_waccs(self, lat, lon, solar_fraction):
        
        # Start loop timer
        loop_start = time.time()
        self.high_seas = self.remove_high_seas()
            
        # Evaluate nature of gridpoint
        high_seas_status = self.high_seas.sel(latitude=lat, longitude=lon)
        landmask = self.geodata['land'].sel(latitude=lat, longitude=lon)

        # Check if location is sea
        if high_seas_status == True:
            return None
        
        # If solar is being examined, check if the location is in the sea
        if solar_fraction > 0:
            if np.isnan(landmask) == True:
                return None
            
        # Get electricity prices
        electricity_price = self.get_electricity_price(lat, lon)
        
        # Get renewables data at each gridpoint
        def get_gridpoint(data, lat, lon, geodata=None):
            gridpoint = data.sel(longitude=lon, latitude=lat)
            gridpoint = gridpoint.expand_dims(latitude=[lat], longitude=[lon])
            if geodata == "True":
                gridpoint = gridpoint.transpose("latitude", "longitude")
            else:
                gridpoint = gridpoint.transpose("time", "latitude", "longitude")
            
            return gridpoint
        
        solar_gridpoint = get_gridpoint(self.solar_data, lat, lon)
        wind_gridpoint = get_gridpoint(self.wind_data, lat, lon)
        geodata_gridpoint = get_gridpoint(self.geodata, lat, lon, "True")
        
        # Specify the bounds
        low_bound = 0.01 
        upp_bound = 0.5
        bounds = [(low_bound, upp_bound)]
                               
        # Calculate result
        if np.isnan(electricity_price):
            return None
        else:
            result = minimize(self.country_waccs_objective_function, x0=[0.1], args= (geodata_gridpoint, solar_gridpoint, wind_gridpoint, solar_fraction, electricity_price), bounds=bounds, method='powell')
            
            try: 
                calculated_rate = result.x[0]
            except: 
                return None
            else:  
                # Store results
                aggregated_results = self.parallel_levelised_cost(geodata_gridpoint,solar_gridpoint, wind_gridpoint, solar_fraction, calculated_rate)
        
                # Creating DataArray for 'calculated_irr'
                calculated_irr = xr.DataArray(
    data=[[calculated_rate]],  # Example data, replace with your actual calculated_irr values
    dims=('latitude', 'longitude'),
    coords={'latitude': aggregated_results.latitude.values, 'longitude': aggregated_results.longitude.values}
)
        
        
                aggregated_results['calculated_irr'] = calculated_irr
                               
        return aggregated_results
    

    def get_electricity_price(self, lat, lon):
        
         # Retrieve CSV file with mapping of countries and waccs
        electricity_prices = self.electricity_prices
        geodata = self.geodata
        land_value = geodata['land'].sel({'latitude': lat, 'longitude': lon}).values 
        
        
        # Retrieve offshore mask
        if np.isnan(land_value):
            sea_value = geodata['sea'].sel({'latitude': lat, 'longitude': lon}).values 
            if np.isnan(sea_value):
                country_price = np.nan
            else:
                country_row = electricity_prices.loc[electricity_prices['country'] == sea_value]
                if country_row.empty:
                    country_price = np.nan
                else:
                    country_price = country_row.loc[country_row.index[0],'Electricity_Price']      
        else: 
            country_row = electricity_prices.loc[electricity_prices['country'] == land_value]
            if country_row.empty:
                    country_price = np.nan
            else:
                country_price = country_row.loc[country_row.index[0],'Electricity_Price']
    
        
        
        return float(country_price)/100
    
    
    def get_eu_wholesale_prices(self, lat, lon):
        
         # Retrieve CSV file with mapping of countries and waccs
        wholesale_prices = self.eu_wholesale_prices
        uk_prices = self.uk_wholesale_prices
        geodata = self.geodata
        land_value = geodata['land'].sel({'latitude': lat, 'longitude': lon}).values 
        
        
        # Retrieve offshore mask
        if np.isnan(land_value):
            land_value = None
            sea_value = geodata['sea'].sel({'latitude': lat, 'longitude': lon}).values 
            if np.isnan(sea_value):
                country_price = np.nan
            else:
                country_prices= wholesale_prices.loc[wholesale_prices['country code'] == sea_value, ['Datetime (UTC)', 'Price (EUR/MWhe)']].copy()
                if country_prices.empty:
                    if sea_value == 76:
                        country_prices = uk_prices[['Price (£/MWh, hourly)', 'Datetime']].copy()
                        price_data = country_prices.copy()
                    else:
                        price_data = np.nan
                        return None
                else:
                    price_data = country_prices.copy()
        else: 
            sea_value = None
            country_prices= wholesale_prices.loc[wholesale_prices['country code'] == land_value, ['Datetime (UTC)', 'Price (EUR/MWhe)']].copy()
            if country_prices.empty:
                if land_value == 76:
                    country_prices = uk_prices[['Price (£/MWh, hourly)', 'Datetime']].copy()
                    price_data = country_prices.copy()
                else:
                    price_data = np.nan
                    return None
            else:
                price_data = country_prices.copy()
        if sea_value is None:
            country_value = land_value
        else:
            country_value = sea_value
            
        if country_value == 143:
            price_data = np.nan
            return None
        
        if country_value == 76:
            price_data['time'] = price_data['Datetime']
            price_data['latitude'] = [lat] * len(price_data)
            price_data['longitude'] = [lon] * len(price_data)
            df_indexed = price_data.set_index('time')
            price_data['Price (USD/kWh)'] = price_data['Price (£/MWh, hourly)']*1.25/1000
            
            price_dataset = xr.Dataset({
    'Price (USD/kWh)': (('time',), price_data['Price (USD/kWh)'].values)
}, coords={
    'time': pd.to_datetime(price_data['time'], format='%d/%m/%Y %H:%M'),
     #'time': pd.to_datetime(price_data['time'], format='%Y-%m-%d %H:%M:%S'),
    'latitude': lat,
    'longitude': lon
})
            latitude = price_dataset ['latitude'].values
            longitude = price_dataset ['longitude'].values

            # Use expand_dims to add dimensions of latitude and longitude to the 'Price (USD/kWh)' variable
            price_expanded = price_dataset.expand_dims(latitude=[latitude], longitude=[longitude])

        else:    
            # Process country wholesale prices
            price_data['Datetime (UTC)'] = pd.to_datetime(price_data['Datetime (UTC)'])

            # Extract hour
            price_data['time'] = price_data['Datetime (UTC)'].dt.strftime('%Y-%m-%d') + ' ' + price_data['Datetime (UTC)'].dt.hour.astype(str) + ':30:00'

            # Create latitude and longitude arrays (replace with your desired location)
            price_data['latitude'] = [lat] * len(price_data)
            price_data['longitude'] = [lon] * len(price_data)
            df_indexed = price_data.set_index('time')
            price_data['Price (USD/kWh)'] = price_data['Price (EUR/MWhe)']*1.2/1000

            # Create xarray dataset
            # IN USD/KWh rather than EUR/MWh
            price_dataset = xr.Dataset({
    'Price (USD/kWh)': (('time',), price_data['Price (USD/kWh)'].values)
}, coords={
    'time': pd.to_datetime(price_data['time']),
    'latitude': lat,
    'longitude': lon
})
            latitude = price_dataset ['latitude'].values
            longitude = price_dataset ['longitude'].values

            # Use expand_dims to add dimensions of latitude and longitude to the 'Price (USD/kWh)' variable
            price_expanded = price_dataset.expand_dims(latitude=[latitude], longitude=[longitude])
        
        return price_expanded
    
    
    
    def estimate_eu_waccs(self, lat, lon, solar_fraction, five_years=None, five_years_continuous=None):
        
        # Start loop timer
        loop_start = time.time()
        self.high_seas = self.remove_high_seas()
            
        # Evaluate nature of gridpoint
        high_seas_status = self.high_seas.sel(latitude=lat, longitude=lon)
        landmask = self.geodata['land'].sel(latitude=lat, longitude=lon)

        # Check if location is sea
        if high_seas_status == True:
            return None
        
        # If solar is being examined, check if the location is in the sea
        if solar_fraction > 0:
            if np.isnan(landmask) == True:
                return None
            
        # Get electricity prices
        electricity_prices = self.get_eu_wholesale_prices(lat, lon) # IN USD/kWh
        
        
        # Get renewables data at each gridpoint
        def get_gridpoint(data, lat, lon, geodata=None):
            gridpoint = data.sel(longitude=lon, latitude=lat)
            gridpoint = gridpoint.expand_dims(latitude=[lat], longitude=[lon])
            if geodata == "True":
                gridpoint = gridpoint.transpose("latitude", "longitude")
            else:
                gridpoint = gridpoint.transpose("time", "latitude", "longitude")
            
            return gridpoint
        
        solar_gridpoint = get_gridpoint(self.solar_data, lat, lon)
        wind_gridpoint = get_gridpoint(self.wind_data, lat, lon)
        geodata_gridpoint = get_gridpoint(self.geodata, lat, lon, "True")
        
        # Specify the bounds
        low_bound = 0.01 
        upp_bound = 0.25
        bounds = [(low_bound, upp_bound)]
                               
        # Calculate result
        if isinstance(electricity_prices, xr.Dataset):
            wholesale_prices = electricity_prices['Price (USD/kWh)'] # IN USD/kWh
                
            #result = minimize(self.eu_waccs_objective_function, x0=[0.1], tol=0.5, args= (geodata_gridpoint, solar_gridpoint, wind_gridpoint, solar_fraction, wholesale_prices), bounds=bounds, method='powell')
            result = minimize_scalar(self.eu_waccs_objective_function,bounds=(low_bound, upp_bound), args=(geodata_gridpoint, solar_gridpoint, wind_gridpoint, solar_fraction, wholesale_prices, five_years, five_years_continuous), method='bounded')
            try: 
                calculated_rate = result.x
            except: 
                print("Issues calculating rate")
                return None
            else:  
                # Store results
                aggregated_results = self.parallel_levelised_cost(geodata_gridpoint,solar_gridpoint, wind_gridpoint, solar_fraction, calculated_rate)
        
                # Creating DataArray for 'calculated_irr'
                calculated_irr = xr.DataArray(
    data=[[calculated_rate]],  # Example data, replace with your actual calculated_irr values
    dims=('latitude', 'longitude'),
    coords={'latitude': aggregated_results.latitude.values, 'longitude': aggregated_results.longitude.values}
)
                
                # Add IRR into the results
                aggregated_results['calculated_irr'] = calculated_irr
                
                       
                ## Extract revenue by year and store
                if five_years_continuous is not None:
                    revenue, yearly_prices = self.economic_profile_class.calculate_revenue_5_years(geodata_gridpoint, solar_gridpoint, wind_gridpoint, solar_fraction, wholesale_prices)
                else:
                    revenue, yearly_prices = self.economic_profile_class.calculate_revenue(geodata_gridpoint, solar_gridpoint, wind_gridpoint, solar_fraction, wholesale_prices, five_years=five_years)
                    
                ## Add revenue to results
                revenue_extended = self.extend_to_lifetime(revenue, self.lifetime)
                prices_extended = self.extend_to_lifetime(yearly_prices, self.lifetime)
                years_revenue = revenue_extended.year
                aggregated_results['year'] = years_revenue
                aggregated_results['yearly_revenue'] = revenue_extended
                aggregated_results['yearly_prices'] = prices_extended
            
                
                # Calculate the LCOE at the wacc rate
                #lcoe_results = self.parallel_levelised_cost(geodata_gridpoint,solar_gridpoint, wind_gridpoint, solar_fraction)
                #aggregated_results['levelised_cost (IRENA WACC)'] = lcoe_results['levelised_cost']
        else:
            return None

                               
        return aggregated_results
    
                               
                               
    def country_waccs_objective_function(self, specified_rate, geodata, solar_data, wind_data, solar_fraction, electricity_price):
        
        """ Function to calculate the difference between the LCOE and electricity price at the location """
        
        # Run levelised cost function  
        results = self.parallel_levelised_cost(geodata, solar_data, wind_data, solar_fraction, specified_rate)
        
        # Calculate electricity cost that is wholesale, using Ofgem's proportions (2019)
        wholesale_price = electricity_price * 0.4154704944

        # Extract the LCOE
        lcoe = results['levelised_cost'].values[0][0]
            
        # Calculate the difference
        difference = abs(wholesale_price - lcoe)
        
        return np.round(difference, decimals = 3)
    
    
    
    
        

    
    
    def eu_waccs_objective_function(self, specified_rate, geodata, solar_data, wind_data, solar_fraction, electricity_prices, five_years=None, five_years_continuous=None):
        
        """ Function to calculate the difference between the LCOE and discounted wholesale revenue at the location """
        
        # Run levelised cost function  
        results = self.parallel_levelised_cost(geodata, solar_data, wind_data, solar_fraction, specified_rate, five_years, five_years_continuous)
        
        # Calculate revenue based on prices multiplied by production
        solar_profile = solar_data * self.renewables_capacity # IN KWh
        wind_profile = wind_data * self.renewables_capacity # IN KWh
        revenue, yearly_prices = self.economic_profile_class.calculate_revenue(geodata, solar_profile, wind_profile, solar_fraction, electricity_prices, five_years=five_years)
        if five_years_continuous is not None:
            revenue, yearly_prices = self.economic_profile_class.calculate_revenue_5_years(geodata, solar_profile, wind_profile, solar_fraction, electricity_prices)
        
        
        # Extend the electricity revenue to lifetime
        years = revenue.sizes['year'] - 1
        
        # If the size of the data is less than the lifetime, duplicate the data
        if years < self.lifetime:
            total_revenue = self.extend_to_lifetime(revenue, self.lifetime)
        
        # Discount the revenue
        discounted_revenue = self.discount_with_single_rate(total_revenue, specified_rate) # IN USD for 1 MW
        discounted_total_revenue = discounted_revenue.sum(dim='year')
        
        # Extract the total costs and discount them
        discounted_costs = self.discount_with_single_rate(results['total_costs'], specified_rate)  # IN USD for 1 MW
        discounted_total_costs = discounted_costs.sum(dim='year')
            
        # Calculate the difference
        difference = abs(discounted_total_revenue.values - discounted_total_costs.values)
        return np.round(difference[0][0], decimals = -1)
    
    def parallel_wacc_calculation(self, num_cores, solar_fraction):
        
        start_time = time.time()
        latitudes = self.solar_data.latitude.values
        longitudes = self.solar_data.longitude.values
        
        # Create a list of arguments for each grid point
        grid_point_args = []
        for count_lat, lat in enumerate(latitudes):
            for count_lon, lon in enumerate(longitudes):
                grid_point_args.append((lat, lon))
    
        # Use joblib to parallelize the processing of grid points
        parallel_results = Parallel(n_jobs=num_cores, verbose=20)(delayed(self.estimate_eu_waccs)(solar_fraction=solar_fraction, lat=lat, lon=lon, five_years="True") for lat, lon in grid_point_args)

        # Get the first non empty result
        first_result = next((result for result in parallel_results if result is not None), None)

        # Unpack results
        combined_dataset = None
        for result in parallel_results:
            if result is not None:
                if combined_dataset is None:
                    combined_dataset = result
                else:
                    combined_dataset = combined_dataset.combine_first(result)
            else:
                # If the result is None, create a dataset filled with NaNs
                nan_dataset = xr.zeros_like(first_result)  
                if combined_dataset is None:
                    combined_dataset = nan_dataset
                else:
                    combined_dataset = combined_dataset.combine_first(result)
        
        return combined_dataset
    
    
    def save_specified_results(self, output_folder, lat_lon, results, solar_capex, wind_capex, solar_fraction, wacc=None, continuous=None):
        
        if solar_fraction == 1:
            filename_str = "Solar_" + f"{solar_capex:.0f}" + "USD_" + str(lat_lon[0]) + '_' + str(lat_lon[1]) + '_' + str(lat_lon[2]) + '_' + str(lat_lon[3]) 
        elif solar_fraction == 0: 
            filename_str = "Wind_" + f"{wind_capex:.0f}" + "USD_" + str(lat_lon[0]) + '_' + str(lat_lon[1]) + '_' + str(lat_lon[2]) + '_' + str(lat_lon[3]) 
        else:
            filename_str = "Solar_" + f"{solar_fraction * 100:.0f}" + "%_" + f"{solar_capex:.0f}_" + f"{wind_capex:.0f}"+ "USD_" + str(lat_lon[0]) + '_' + str(lat_lon[1]) + '_' + str(lat_lon[2]) + '_' + str(lat_lon[3]) 
        
        if wacc is not None:
            filename_str = filename_str + "WACC_Estimate"
            
        if continuous is not None:
            filename_str = filename_str + "_5YrContinuous"
            
        # Output the file
        results.to_netcdf(output_folder + filename_str + '.nc')
        
            
            
# CODE TO RUN

# Specify Latitude and Longitude & Slice Sizes
n_slices = 1
lat_lon =  [48, 60, -12, 4]
slice_size = (lat_lon[1] - lat_lon[0])/n_slices



# Set up folder paths
shared_folder_path = "/Users/lukehatton/Green Hydrogen 2024/"
running_folder = "/Users/lukehatton/Documents/Imperial PhD/Analysis/LCOE Modelling/"
renewable_profiles_path = shared_folder_path + "/MERRA2_INPUTS/"
solar_path = renewable_profiles_path + "Solar_CF/"
wind_path = renewable_profiles_path + "Wind_CF/"
input_data_path = shared_folder_path + "/DATA/"
output_folder = running_folder + "/OUTPUT_FOLDER/"

# Set the conditions for the model run
solar_capex = 990 # Set to the difference in solar fraction being run 
wind_capex = 1500 # Set to either PEM or Alkaline
num_cores = 6 # Set to number of cores to use for each Renewable Model case
solar_fraction = 1 # Set to solar fraction
for i in np.linspace(0, n_slices-1, n_slices).astype(int):
    start_lat = lat_lon[0]+i*slice_size
    end_lat = lat_lon[0]+(i+1)*slice_size
    print(f" Latitude slice is between {start_lat} and {end_lat}")
    lat_lon_slice = [start_lat, end_lat, lat_lon[2], lat_lon[3]]
    



    start_time = time.time()
    ## Set up files class
    all_files_class = All_Files(lat_lon=lat_lon_slice, solar_path = solar_path, wind_path=wind_path, solar_format = "SOLAR_CF.", wind_format= "WIND_CF.")

    ## Preprocess the files 
    solar_data, wind_data, years = all_files_class.preprocess_combine_yearly()
    solar_profile_array = solar_data['Solar']
    wind_profile_array = wind_data['CF']
    print("Files from Renewables Ninja read in, corrected and combined")
    
        
    # Initialise a RenewablesModel object
    model = RenewablesModel(solar_dataset = solar_profile_array, wind_dataset = wind_profile_array, data_path = input_data_path, params_file = running_folder + "/Data/model_parameters.csv", output_folder = output_folder, electricity_prices = running_folder + "/Data/CountryElecPrices.csv", wholesale_prices = running_folder + "/Data/EuropeanCountryPrices.csv", uk_prices = running_folder + "/Data/UKElectricityPrices.csv")

    # Run parallelised IRR code
    try: 
        wacc_results = model.global_parallel_calculation(num_cores, solar_fraction)
        model.save_specified_results(output_folder = output_folder, results = wacc_results, lat_lon = lat_lon_slice, solar_fraction = solar_fraction, solar_capex = solar_capex, wind_capex = wind_capex, wacc = "WACC")
        end_time = time.time()
        total_time = end_time - start_time
        print(f"Model took {total_time:.0f} seconds to run the WACC model for a slice of size {slice_size:.0f} degrees longitude")      
    except Exception as e:
        # Handle the error here
        print("Error when calling the parallel LCOH calculator")
        error_message = str(e)
            
        # Capture the console output
        with open(output_folder + 'error_log_' + str(start_lat) + '_' + str(end_lat) + '_' + str(lat_lon_slice[2]) + '_' + str(lat_lon_slice[3]) + '.txt', 'w') as f:
            f.write("Error Message:\n" + error_message + '\n')